{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5bf60c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\JIM/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-2-22 torch 1.10.2+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Loading yolo_finger_exp6_F1_0.66.onnx for ONNX Runtime inference...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m onnxruntime-gpu not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 'pip install onnxruntime-gpu' skipped (offline)\n",
      "C:\\Users\\JIM\\anaconda3\\envs\\golden_finger_py38\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:55: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\n",
      "Adding AutoShape... \n",
      "image 1/1: 128x128 4 class0s\n",
      "Speed: 3.4ms pre-process, 39.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 3 class0s\n",
      "Speed: 3.6ms pre-process, 42.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 4 class0s\n",
      "Speed: 3.5ms pre-process, 49.2ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 3 class0s\n",
      "Speed: 4.7ms pre-process, 44.0ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 5 class0s\n",
      "Speed: 4.4ms pre-process, 45.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 11 class0s\n",
      "Speed: 3.6ms pre-process, 43.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 10 class0s\n",
      "Speed: 4.0ms pre-process, 41.6ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 7 class0s\n",
      "Speed: 4.0ms pre-process, 42.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 7 class0s\n",
      "Speed: 4.1ms pre-process, 41.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 9 class0s\n",
      "Speed: 3.1ms pre-process, 44.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 7 class0s\n",
      "Speed: 3.6ms pre-process, 51.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 4 class0s\n",
      "Speed: 4.6ms pre-process, 41.5ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 2 class0s\n",
      "Speed: 4.0ms pre-process, 47.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 5 class0s\n",
      "Speed: 4.0ms pre-process, 40.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 9 class0s\n",
      "Speed: 3.9ms pre-process, 41.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 5 class0s\n",
      "Speed: 4.1ms pre-process, 42.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 5 class0s\n",
      "Speed: 3.6ms pre-process, 43.8ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 4 class0s\n",
      "Speed: 4.0ms pre-process, 40.6ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 10 class0s\n",
      "Speed: 4.0ms pre-process, 44.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 7 class0s\n",
      "Speed: 3.0ms pre-process, 45.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 128x128 10 class0s\n",
      "Speed: 4.0ms pre-process, 44.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom','yolo_finger_exp6_F1_0.66.onnx')  # or yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "# Images\n",
    "PATH='./test_pic/'\n",
    "for pic in pic_list:\n",
    "#   img = 'test_pic/dpc_20220218_026_10.bmp'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "    # Inference\n",
    "    results = model(PATH+pic)\n",
    "\n",
    "    # Results\n",
    "    results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f4f52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "pic_list=os.listdir(\"./test_pic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be130631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 128x128 10 class0s\n",
      "Speed: 4.0ms pre-process, 44.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "models.common.Detections"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=results.print()\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d5aa60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns\\detect\\exp2\u001b[0m\n",
      "Saved results to runs\\detect\\exp2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.crop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c432bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4b8f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0_66_1000_best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\golden_finger_py38\\lib\\site-packages\\torch\\serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[0;32m    606\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m--> 607\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\golden_finger_py38\\lib\\site-packages\\torch\\serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    881\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m--> 882\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\golden_finger_py38\\lib\\site-packages\\torch\\serialization.py:875\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_class\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod_name, name):\n\u001b[0;32m    874\u001b[0m     mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "model=torch.load(\"0_66_1000_best.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e57924d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file constants.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0_66_1000_best.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\golden_finger_py38\\lib\\site-packages\\torch\\jit\\_serialization.py:161\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, _extra_files)\u001b[0m\n\u001b[0;32m    159\u001b[0m cu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mCompilationUnit()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m--> 161\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_ir_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extra_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module_from_buffer(\n\u001b[0;32m    164\u001b[0m         cu, f\u001b[38;5;241m.\u001b[39mread(), map_location, _extra_files\n\u001b[0;32m    165\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file constants.pkl: file not found"
     ]
    }
   ],
   "source": [
    "model = torch.jit.load('0_66_1000_best.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcdbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00acc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
